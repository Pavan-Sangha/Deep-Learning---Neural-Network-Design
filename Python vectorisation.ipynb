{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorisation in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can obtain $z = w^T*x+b$ by using np.dot in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5236\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1,2,3,50,100])\n",
    "y = np.array([3,4,5,10,47])\n",
    "b = 10\n",
    "z = np.dot(x,y)+b\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed up in time for vectorisation\n",
    "* vectorisation exploits parallelisation in both GPU's and CPU's and as a result are a lot faster than for loops. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorised version in milliseconds :9.408950805664062ms\n",
      "looped version in milliseconds :426.32484436035156ms\n",
      "The speed up by using vectorisation is 45.31056152442732 times\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "# initialise two random vectors of dimension 1 million\n",
    "\n",
    "a = np.random.rand(10000000)\n",
    "b = np.random.rand(10000000)\n",
    "\n",
    "# We start with the vectorised version\n",
    "tic = time.time()\n",
    "\n",
    "c = np.dot(a,b)\n",
    "\n",
    "toc = time.time()\n",
    "\n",
    "diff_vectorised = toc - tic\n",
    "\n",
    "print('Vectorised version in milliseconds :'+str(diff_vectorised*1000)+'ms')\n",
    "\n",
    "# Next we try the for loop\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "sum = 0\n",
    "for index in range(1000000):\n",
    "    sum += a[index]*b[index]\n",
    "\n",
    "toc = time.time()\n",
    "\n",
    "diff_looped = toc - tic\n",
    "\n",
    "print('looped version in milliseconds :'+str(diff_looped*1000)+'ms')\n",
    "\n",
    "print('The speed up by using vectorisation is '+str(1/(diff_vectorised/diff_looped))+ ' times')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.48797317e+01 2.68811714e+43 7.38905610e+00]\n"
     ]
    }
   ],
   "source": [
    "v = np.array([2.7,100,2])\n",
    "b = np.exp(v) # elementwise exponential operation\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorising logistic regression forward pass "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Recall we have $m$ training examples $(x_{1},y_{1}),\\ldots,(x_{m},y_{m})$ with $x_{i} \\in \\mathbb{R}^{n_{x}}$\n",
    "* For each example we compute $z_{i} = w^{T}x_{i}+b$ and then $a_{i} = \\sigma(z_{i})$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "\n",
    "n_x = 10    # feature dimensionality\n",
    "m = 3 # training sample size \n",
    "x1 = np.random.rand(n_x)\n",
    "x2 = np.random.rand(n_x)\n",
    "x3 = np.random.rand(n_x)\n",
    "y1 = 0\n",
    "y2 = 1\n",
    "y3 = 0\n",
    "\n",
    "y = np.array([y1,y2,y3])\n",
    "w = np.array([100,2,3,5,10,200,30,1,6,8])   # weights vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.39732429 0.0879649  0.8744926 ]\n",
      " [0.8491405  0.88313677 0.6331414 ]\n",
      " [0.55149249 0.72980439 0.96729557]\n",
      " [0.05238606 0.97006001 0.00266972]\n",
      " [0.34761441 0.69797405 0.64967418]\n",
      " [0.58261928 0.22312668 0.95458838]\n",
      " [0.52374288 0.38721469 0.82597694]\n",
      " [0.93689477 0.07932701 0.41658208]\n",
      " [0.02695664 0.54463197 0.0602862 ]\n",
      " [0.16167373 0.43218378 0.66454221]]\n"
     ]
    }
   ],
   "source": [
    "X = np.stack((x1,x2,x3),axis = -1)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([191.45142765,  97.62858254, 329.91914098])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.dot(w.T,X)+10\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Equivalent to A = [z1,z2,z3]\n",
    "# Since Z values are large a values will be near 1\n",
    "A = sigmoid(z)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorising linear regression backward pass for a single iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Loss Function\n",
    "* Recall we have $m$ training examples $(x_{1},y_{1}),\\ldots,(x_{m},y_{m})$ with $x_{i} \\in \\mathbb{R}^{n_{x}}$\n",
    "* For each example we compute $z_{i} = w^{T}x_{i}+b$ and then $a_{i} = \\sigma(z_{i})$\n",
    "\n",
    "* The loss function w.r.t one example say example $i$ is $L(a_{i},y_{i})=-y_{i}\\mathrm{log}(a_{i})+(1-y_{i})\\mathrm{log}(1-a_{i})$ where $a_{i} = \\sigma(z_{i})$\n",
    "* 'dai' is then $\\frac{\\partial L}{\\partial a_{i}} = \\frac{-y}{a_{i}}+\\frac{1-y}{1-a_{i}}$\n",
    "* 'dzi' is then $\\frac{\\partial L}{\\partial z_{i}} = \\frac{\\partial L}{\\partial a_{i}} \\cdot \\frac{\\partial a_{i}}{\\partial z_{i}} = a_{i}-y$\n",
    "* 'dwi' is then $\\frac{\\partial L}{\\partial w_{i}} = x_{i}dz_{i}$\n",
    "* 'dbi' is then $\\frac{\\partial L}{\\partial b_{i}} = dz_{i}$\n",
    "\n",
    "\n",
    "\n",
    "Cost Function\n",
    "* Now that we have a value for the loss w.r.t a single training example $1 \\leq i \\leq m$. We average to get the cost function $$J(w,b) = \\frac{1}{m} \\sum_{i=1}^{m} L(a^{i},y)$$\n",
    "* We can distribute the partial derivatives across the sum for any variable we are interested in as follows\n",
    "$$ \\frac{\\partial J}{\\partial w_{i}} = \\frac{1}{m} \\sum_{i=1}^{m} \\frac{\\partial}{\\partial w_{i}} L(a_{i},y^{i}) $$\n",
    "* In our example dz = [dz1,dz2,dz3] = [a1-y1,a2-y2,a3-y3] = A-y\n",
    "* $db = \\frac{1}{m} \\sum_{i=1}^{m} dz_{i}$ and we can calculate this as db = 1/m * np.sum(dz) \n",
    "* $dw = 1/m \\cdot X \\cdot dz^{T}$ since $X = [x^1,x^2,\\ldots,x^m]$ \n",
    "\n",
    "Updates \n",
    "\n",
    "* $w = w-\\alpha \\cdot dw$\n",
    "* $b = b-\\alpha \\cdot db$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can now run this code over a number of iterations enclosed in a for loop\n",
    "\n",
    "    num_iters = 1000\n",
    "    for i in range(num_iters):\n",
    "        z = np.dot(w.T,X)+b   #z = w^T X+b\n",
    "        A = \\sigma(Z)\n",
    "        dz = A-y\n",
    "        dw = 1/m * X * dz^T\n",
    "        db = 1/m * np.sum(dz)\n",
    "        \n",
    "        \n",
    "        w = w-\\alpha*dw\n",
    "        b = b-\\alpha*db\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[56.0, 0.0, 10.0,11.2],[34,56,70.0,23],[24,47,11,15]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56.   0.  10.  11.2]\n",
      " [34.  56.  70.  23. ]\n",
      " [24.  47.  11.  15. ]]\n"
     ]
    }
   ],
   "source": [
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[114.  103.   91.   49.2]\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "col_sum = A.sum(axis = 0) # column sum\n",
    "print(col_sum)\n",
    "print(col_sum.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[114.  103.   91.   49.2]]\n",
      "(1, 4)\n"
     ]
    }
   ],
   "source": [
    "print(col_sum.reshape(1,4))\n",
    "print(col_sum.reshape(1,4).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[49.12280702,  0.        , 10.98901099, 22.76422764],\n",
       "       [29.8245614 , 54.36893204, 76.92307692, 46.74796748],\n",
       "       [21.05263158, 45.63106796, 12.08791209, 30.48780488]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage = 100*A/col_sum.reshape(1,4) # reshapes the array\n",
    "percentage\n",
    "# divides a (3,4) matrix by a (1,4) matrix\n",
    "# 3 lots of (1,4) rows and we divide each row pairwise by another (1,4) matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1)\n",
      "[[101]\n",
      " [102]\n",
      " [103]\n",
      " [104]]\n"
     ]
    }
   ],
   "source": [
    "B = np.array([[1],[2],[3],[4]])\n",
    "print(B.shape)\n",
    "print(B+100)\n",
    "C = np.array([100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[101],\n",
       "       [102],\n",
       "       [103],\n",
       "       [104]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B+C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[103,  54,  65],\n",
       "       [101,  52,  63]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = np.array([[3,4,5],[1,2,3]])\n",
    "E = np.array([[100,50,60]])\n",
    "D+E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16537173 0.45427248 0.32270944 0.87369049 0.05063514]\n"
     ]
    }
   ],
   "source": [
    "a = np.random.rand(5) \n",
    "print(a)\n",
    "# this is a rank 1 array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.73489608]\n",
      " [0.49890107]\n",
      " [0.25980254]\n",
      " [0.92120178]\n",
      " [0.70169483]]\n"
     ]
    }
   ],
   "source": [
    "b = np.random.rand(5,1) \n",
    "print(b)\n",
    "# this is a (5,1) column vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.27267061 0.27367064 0.08902385 0.24000531 0.93662333]]\n"
     ]
    }
   ],
   "source": [
    "c = np.random.rand(1,5)\n",
    "print(c)\n",
    "# this is a (1,5) row vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
